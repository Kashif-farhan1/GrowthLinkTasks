{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oDJUD66E1Vyz"
      },
      "outputs": [],
      "source": [
        "#âœ… Step 1: Upload ZIP Files and Extract\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "# ðŸ“‚ Upload ZIP files manually in Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload train_v2.zip, test_v2.zip, validate_v2.zip\n",
        "\n",
        "# ðŸ“¦ Unzip all\n",
        "for filename in uploaded.keys():\n",
        "    with ZipFile(filename, 'r') as zip_ref:\n",
        "        folder_name = filename.replace('.zip', '')\n",
        "        zip_ref.extractall('train_v2')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load Metadata CSV (written_name_test_v2.csv or similar)\n",
        "import pandas as pd\n",
        "\n",
        "# Upload metadata CSV file\n",
        "files.upload()  # Upload 'written_name_test_v2.csv' or respective CSV\n",
        "\n",
        "# Load into DataFrame\n",
        "df = pd.read_csv(\"written_name_test_v2.csv\")\n",
        "df.columns = df.columns.str.strip()\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "4hpje9sI1bWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Step 3: Display Sample Handwritten Images\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "image_files = df['train_v2'].tolist()\n",
        "labels = df['IDENTITY'].tolist()\n",
        "sample_path = '/content/train_v2'  # Adjust if you are using other folders\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(9):\n",
        "    img_path = os.path.join(sample_path, image_files[i])\n",
        "    img = Image.open(img_path)\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(f\"Label: {labels[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "F2k2NgEz1rXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ],
      "metadata": {
        "id": "U5WjNAM22A0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Preprocess Images\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "image_data = []\n",
        "target_labels = []\n",
        "\n",
        "for i in range(len(image_files)):\n",
        "    try:\n",
        "        img_path = os.path.join(sample_path, image_files[i])\n",
        "        img = Image.open(img_path).convert('L')  # grayscale\n",
        "        img = img.resize((128, 32))  # Resize uniformly\n",
        "        img_array = img_to_array(img) / 255.0\n",
        "        image_data.append(img_array)\n",
        "        target_labels.append(labels[i])\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "X = np.array(image_data)\n",
        "print(\"Image Data Shape:\", X.shape)\n",
        "\n",
        "# Convert labels to encoded classes\n",
        "label_enc = LabelEncoder()\n",
        "y_encoded = label_enc.fit_transform(target_labels)\n",
        "y = to_categorical(y_encoded)\n"
      ],
      "metadata": {
        "id": "n77J-HLA15R2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Step 5: Train-Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "Vjwe09UJ2Bf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Step 6: Build Model (CNN + LSTM for Handwritten Sequence Prediction)\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LSTM, TimeDistributed, Reshape\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# CNN Feature Extraction\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 128, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "\n",
        "# Reshape for RNN\n",
        "model.add(Reshape((1, -1)))\n",
        "\n",
        "# LSTM Sequence Modeling\n",
        "model.add(LSTM(128, return_sequences=False))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "aL-6fLMi2Fkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Step 7: Train the Model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=15, batch_size=32)\n"
      ],
      "metadata": {
        "id": "EaRG_DMq2KhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Evaluate the Model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title(\"Model Accuracy Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fB3tis9U2Nx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Predict on Sample Data\n",
        "sample_idx = 10\n",
        "sample_img = np.expand_dims(X_val[sample_idx], axis=0)\n",
        "pred_label = model.predict(sample_img)\n",
        "decoded_label = label_enc.inverse_transform([np.argmax(pred_label)])\n",
        "\n",
        "plt.imshow(X_val[sample_idx].reshape(32, 128), cmap='gray')\n",
        "plt.title(f\"Predicted: {decoded_label[0]}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fst4yint2R33"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}